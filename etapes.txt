- Enlever les ponctuations améliore la perfo
- Stem+ lem améliore la perfo

/usr/bin/python3 /home/chiheb/PycharmProjects/TP-3/EmoContext.py
/home/chiheb/.local/lib/python3.6/site-packages/sklearn/externals/joblib/externals/cloudpickle/cloudpickle.py:47: DeprecationWarning: the imp module is deprecated in favour of importlib; see the module's documentation for alternative uses
  import imp
Le fichier "corpus/train_cln_1T_nrm_1_AP.txt "existe déja!
Le fichier "corpus/train_cln_1T_nrm_1_SP.txt "existe déja!
Le fichier "corpus/train_cln_3T_nrm_1_AP.txt "existe déja!
Le fichier "corpus/train_cln_3T_nrm_1_SP.txt "existe déja!
Le fichier "corpus/train_cln_1T_nrm_2_AP.txt "existe déja!
Le fichier "corpus/train_cln_1T_nrm_2_SP.txt "existe déja!
Le fichier "corpus/train_cln_3T_nrm_2_AP.txt "existe déja!
Le fichier "corpus/train_cln_3T_nrm_2_SP.txt "existe déja!
Le fichier "corpus/train_cln_1T_nrm_3_AP.txt "existe déja!
Le fichier "corpus/train_cln_1T_nrm_3_SP.txt "existe déja!
Le fichier "corpus/train_cln_3T_nrm_3_AP.txt "existe déja!
Le fichier "corpus/train_cln_3T_nrm_3_SP.txt "existe déja!
Logistic regression
Tester avec ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
/home/chiheb/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.
  FutureWarning)
/home/chiheb/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.
  "this warning.", FutureWarning)
62.10
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.66
Validation des résultats pour 24000 attributs
61.66
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.98
Validation des résultats pour 6000 attributs
62.32
Validation des résultats pour 9000 attributs
62.87
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.76
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.65
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.66
Validation des résultats pour 12000 attributs
61.99
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.87
Validation des résultats pour 24000 attributs
62.98
Validation des résultats pour 27000 attributs
62.54
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.44
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
61.10
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.88
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.88
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.99
Validation des résultats pour 12000 attributs
62.10
Validation des résultats pour 15000 attributs
62.10
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.32
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.43
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
62.21
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.32
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
60.99
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.99
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.99
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.11
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
61.22
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.10
Validation des résultats pour 21000 attributs
61.10
Validation des résultats pour 24000 attributs
61.10
Validation des résultats pour 27000 attributs
61.10
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.88
Validation des résultats pour 18000 attributs
61.88
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.33
Validation des résultats pour 9000 attributs
62.54
Validation des résultats pour 12000 attributs
62.43
Validation des résultats pour 15000 attributs
62.21
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.33
Validation des résultats pour 24000 attributs
61.33
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
63.20
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.65
Validation des résultats pour 24000 attributs
62.65
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.99
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.77
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.22
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.66
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.10
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.33
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.33
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
79.47
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
80.13
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.12
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
80.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.15
Validation des résultats pour 18000 attributs
78.15
Validation des résultats pour 21000 attributs
78.15
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.15
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.15
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
82.12
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.79
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
81.79
Validation des résultats pour 27000 attributs
81.79
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.15
Validation des résultats pour 6000 attributs
76.82
Validation des résultats pour 9000 attributs
76.82
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
79.80
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.79
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.81
Validation des résultats pour 18000 attributs
78.81
Validation des résultats pour 21000 attributs
78.81
Validation des résultats pour 24000 attributs
78.81
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
76.16
Validation des résultats pour 15000 attributs
76.16
Validation des résultats pour 18000 attributs
76.16
Validation des résultats pour 21000 attributs
76.16
Validation des résultats pour 24000 attributs
76.16
Validation des résultats pour 27000 attributs
76.16
Validation des résultats pour 30000 attributs
76.16
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.49
Validation des résultats pour 9000 attributs
75.50
Validation des résultats pour 12000 attributs
75.50
Validation des résultats pour 15000 attributs
75.83
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.82
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
75.83
Validation des résultats pour 15000 attributs
76.49
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
76.49
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
Tester sans ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.44
Validation des résultats pour 18000 attributs
61.44
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.44
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.76
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.43
Validation des résultats pour 12000 attributs
63.09
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.65
Validation des résultats pour 21000 attributs
62.21
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
62.65
Validation des résultats pour 30000 attributs
62.76
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.32
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.10
Validation des résultats pour 12000 attributs
62.32
Validation des résultats pour 15000 attributs
62.65
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
61.10
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.88
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.88
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.55
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.77
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.77
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.99
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.09
Validation des résultats pour 12000 attributs
63.20
Validation des résultats pour 15000 attributs
62.87
Validation des résultats pour 18000 attributs
62.32
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.66
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
62.21
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
61.33
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.55
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.44
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.55
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.66
Validation des résultats pour 18000 attributs
60.66
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.66
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.22
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.32
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.55
Validation des résultats pour 12000 attributs
61.55
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
59.89
Validation des résultats pour 9000 attributs
60.11
Validation des résultats pour 12000 attributs
60.11
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
60.00
Validation des résultats pour 24000 attributs
60.00
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.00
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.22
Validation des résultats pour 18000 attributs
60.11
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.55
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.22
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
59.89
Validation des résultats pour 24000 attributs
60.22
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.33
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.47
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.45
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.45
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.46
Validation des résultats pour 18000 attributs
82.78
Validation des résultats pour 21000 attributs
82.45
Validation des résultats pour 24000 attributs
82.78
Validation des résultats pour 27000 attributs
82.78
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
82.78
Validation des résultats pour 12000 attributs
82.78
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
77.48
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.46
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.13
Validation des résultats pour 9000 attributs
81.79
Validation des résultats pour 12000 attributs
81.46
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
82.45
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.46
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.79
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
77.15
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.46
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.45
Validation des résultats pour 27000 attributs
82.12
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.80
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.79
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
78.81
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.14
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.81
Validation des résultats pour 12000 attributs
77.81
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
77.81
Validation des résultats pour 24000 attributs
77.81
Validation des résultats pour 27000 attributs
77.81
Validation des résultats pour 30000 attributs
77.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
78.15
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
79.80
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.48
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------

Tester avec ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.66
Validation des résultats pour 24000 attributs
61.66
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.98
Validation des résultats pour 6000 attributs
62.32
Validation des résultats pour 9000 attributs
62.87
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.76
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.65
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.66
Validation des résultats pour 12000 attributs
61.99
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.87
Validation des résultats pour 24000 attributs
62.98
Validation des résultats pour 27000 attributs
62.54
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.44
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
61.10
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.88
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.88
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.99
Validation des résultats pour 12000 attributs
62.10
Validation des résultats pour 15000 attributs
62.10
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.32
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.43
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
62.21
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.32
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
60.99
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.99
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.99
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.11
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
61.22
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.10
Validation des résultats pour 21000 attributs
61.10
Validation des résultats pour 24000 attributs
61.10
Validation des résultats pour 27000 attributs
61.10
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.88
Validation des résultats pour 18000 attributs
61.88
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.33
Validation des résultats pour 9000 attributs
62.54
Validation des résultats pour 12000 attributs
62.43
Validation des résultats pour 15000 attributs
62.21
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.33
Validation des résultats pour 24000 attributs
61.33
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
63.20
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.65
Validation des résultats pour 24000 attributs
62.65
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.99
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.77
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.22
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.66
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.10
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.33
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.33
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
79.47
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
80.13
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.12
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
80.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.15
Validation des résultats pour 18000 attributs
78.15
Validation des résultats pour 21000 attributs
78.15
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.15
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.15
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
82.12
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.79
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
81.79
Validation des résultats pour 27000 attributs
81.79
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.15
Validation des résultats pour 6000 attributs
76.82
Validation des résultats pour 9000 attributs
76.82
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
79.80
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.79
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.81
Validation des résultats pour 18000 attributs
78.81
Validation des résultats pour 21000 attributs
78.81
Validation des résultats pour 24000 attributs
78.81
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
76.16
Validation des résultats pour 15000 attributs
76.16
Validation des résultats pour 18000 attributs
76.16
Validation des résultats pour 21000 attributs
76.16
Validation des résultats pour 24000 attributs
76.16
Validation des résultats pour 27000 attributs
76.16
Validation des résultats pour 30000 attributs
76.16
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.49
Validation des résultats pour 9000 attributs
75.50
Validation des résultats pour 12000 attributs
75.50
Validation des résultats pour 15000 attributs
75.83
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.82
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
75.83
Validation des résultats pour 15000 attributs
76.49
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
76.49
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
Tester sans ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.44
Validation des résultats pour 18000 attributs
61.44
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.44
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.76
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.43
Validation des résultats pour 12000 attributs
63.09
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.65
Validation des résultats pour 21000 attributs
62.21
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
62.65
Validation des résultats pour 30000 attributs
62.76
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.32
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.10
Validation des résultats pour 12000 attributs
62.32
Validation des résultats pour 15000 attributs
62.65
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
61.10
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.88
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.88
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.55
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.77
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.77
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.99
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.09
Validation des résultats pour 12000 attributs
63.20
Validation des résultats pour 15000 attributs
62.87
Validation des résultats pour 18000 attributs
62.32
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.66
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
62.21
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
61.33
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.55
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.44
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.55
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.66
Validation des résultats pour 18000 attributs
60.66
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.66
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.22
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.32
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.55
Validation des résultats pour 12000 attributs
61.55
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
59.89
Validation des résultats pour 9000 attributs
60.11
Validation des résultats pour 12000 attributs
60.11
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
60.00
Validation des résultats pour 24000 attributs
60.00
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.00
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.22
Validation des résultats pour 18000 attributs
60.11
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.55
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.22
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
59.89
Validation des résultats pour 24000 attributs
60.22
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.33
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.47
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.45
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.45
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.46
Validation des résultats pour 18000 attributs
82.78
Validation des résultats pour 21000 attributs
82.45
Validation des résultats pour 24000 attributs
82.78
Validation des résultats pour 27000 attributs
82.78
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
82.78
Validation des résultats pour 12000 attributs
82.78
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
77.48
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.46
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.13
Validation des résultats pour 9000 attributs
81.79
Validation des résultats pour 12000 attributs
81.46
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
82.45
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.46
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.79
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
77.15
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.46
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.45
Validation des résultats pour 27000 attributs
82.12
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.80
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.79
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
78.81
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.14
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.81
Validation des résultats pour 12000 attributs
77.81
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
77.81
Validation des résultats pour 24000 attributs
77.81
Validation des résultats pour 27000 attributs
77.81
Validation des résultats pour 30000 attributs
77.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
78.15
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
79.80
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.48
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------
MultinomialNB
Tester avec ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.66
Validation des résultats pour 24000 attributs
61.66
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.98
Validation des résultats pour 6000 attributs
62.32
Validation des résultats pour 9000 attributs
62.87
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.76
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.65
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.66
Validation des résultats pour 12000 attributs
61.99
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.87
Validation des résultats pour 24000 attributs
62.98
Validation des résultats pour 27000 attributs
62.54
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.44
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
61.10
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.88
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.88
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.99
Validation des résultats pour 12000 attributs
62.10
Validation des résultats pour 15000 attributs
62.10
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.32
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.43
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
62.21
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.32
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
60.99
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.99
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.99
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.11
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
61.22
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.10
Validation des résultats pour 21000 attributs
61.10
Validation des résultats pour 24000 attributs
61.10
Validation des résultats pour 27000 attributs
61.10
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.88
Validation des résultats pour 18000 attributs
61.88
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.33
Validation des résultats pour 9000 attributs
62.54
Validation des résultats pour 12000 attributs
62.43
Validation des résultats pour 15000 attributs
62.21
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.33
Validation des résultats pour 24000 attributs
61.33
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
63.20
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.65
Validation des résultats pour 24000 attributs
62.65
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.99
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.77
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.22
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.66
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.10
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.33
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.33
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
79.47
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
80.13
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.12
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
80.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.15
Validation des résultats pour 18000 attributs
78.15
Validation des résultats pour 21000 attributs
78.15
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.15
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.15
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
82.12
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.79
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
81.79
Validation des résultats pour 27000 attributs
81.79
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.15
Validation des résultats pour 6000 attributs
76.82
Validation des résultats pour 9000 attributs
76.82
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
79.80
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.79
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.81
Validation des résultats pour 18000 attributs
78.81
Validation des résultats pour 21000 attributs
78.81
Validation des résultats pour 24000 attributs
78.81
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
76.16
Validation des résultats pour 15000 attributs
76.16
Validation des résultats pour 18000 attributs
76.16
Validation des résultats pour 21000 attributs
76.16
Validation des résultats pour 24000 attributs
76.16
Validation des résultats pour 27000 attributs
76.16
Validation des résultats pour 30000 attributs
76.16
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.49
Validation des résultats pour 9000 attributs
75.50
Validation des résultats pour 12000 attributs
75.50
Validation des résultats pour 15000 attributs
75.83
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.82
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
75.83
Validation des résultats pour 15000 attributs
76.49
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
76.49
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
Tester sans ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.44
Validation des résultats pour 18000 attributs
61.44
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.44
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.76
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.43
Validation des résultats pour 12000 attributs
63.09
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.65
Validation des résultats pour 21000 attributs
62.21
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
62.65
Validation des résultats pour 30000 attributs
62.76
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.32
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.10
Validation des résultats pour 12000 attributs
62.32
Validation des résultats pour 15000 attributs
62.65
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
61.10
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.88
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.88
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.55
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.77
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.77
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.99
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.09
Validation des résultats pour 12000 attributs
63.20
Validation des résultats pour 15000 attributs
62.87
Validation des résultats pour 18000 attributs
62.32
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.66
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
62.21
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
61.33
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.55
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.44
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.55
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.66
Validation des résultats pour 18000 attributs
60.66
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.66
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.22
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.32
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.55
Validation des résultats pour 12000 attributs
61.55
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
59.89
Validation des résultats pour 9000 attributs
60.11
Validation des résultats pour 12000 attributs
60.11
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
60.00
Validation des résultats pour 24000 attributs
60.00
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.00
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.22
Validation des résultats pour 18000 attributs
60.11
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.55
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.22
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
59.89
Validation des résultats pour 24000 attributs
60.22
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.33
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.47
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.45
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.45
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.46
Validation des résultats pour 18000 attributs
82.78
Validation des résultats pour 21000 attributs
82.45
Validation des résultats pour 24000 attributs
82.78
Validation des résultats pour 27000 attributs
82.78
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
82.78
Validation des résultats pour 12000 attributs
82.78
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
77.48
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.46
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.13
Validation des résultats pour 9000 attributs
81.79
Validation des résultats pour 12000 attributs
81.46
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
82.45
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.46
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.79
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
77.15
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.46
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.45
Validation des résultats pour 27000 attributs
82.12
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.80
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.79
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
78.81
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.14
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.81
Validation des résultats pour 12000 attributs
77.81
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
77.81
Validation des résultats pour 24000 attributs
77.81
Validation des résultats pour 27000 attributs
77.81
Validation des résultats pour 30000 attributs
77.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
78.15
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
79.80
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.48
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------

Tester avec ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=None, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.66
Validation des résultats pour 24000 attributs
61.66
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.98
Validation des résultats pour 6000 attributs
62.32
Validation des résultats pour 9000 attributs
62.87
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.76
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.65
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.66
Validation des résultats pour 12000 attributs
61.99
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.87
Validation des résultats pour 24000 attributs
62.98
Validation des résultats pour 27000 attributs
62.54
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.44
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
61.10
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.88
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
61.10
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.88
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.99
Validation des résultats pour 12000 attributs
62.10
Validation des résultats pour 15000 attributs
62.10
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.10
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.32
Validation des résultats pour 12000 attributs
62.76
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
62.10
Validation des résultats pour 27000 attributs
62.10
Validation des résultats pour 30000 attributs
62.43
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
62.21
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
62.32
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.88
Validation des résultats pour 12000 attributs
60.99
Validation des résultats pour 15000 attributs
60.99
Validation des résultats pour 18000 attributs
60.99
Validation des résultats pour 21000 attributs
60.99
Validation des résultats pour 24000 attributs
60.99
Validation des résultats pour 27000 attributs
60.99
Validation des résultats pour 30000 attributs
60.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.11
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
61.22
Validation des résultats pour 21000 attributs
61.22
Validation des résultats pour 24000 attributs
61.22
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
60.55
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
61.22
Validation des résultats pour 15000 attributs
61.22
Validation des résultats pour 18000 attributs
61.10
Validation des résultats pour 21000 attributs
61.10
Validation des résultats pour 24000 attributs
61.10
Validation des résultats pour 27000 attributs
61.10
Validation des résultats pour 30000 attributs
61.22
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.77
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.88
Validation des résultats pour 18000 attributs
61.88
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.33
Validation des résultats pour 9000 attributs
62.54
Validation des résultats pour 12000 attributs
62.43
Validation des résultats pour 15000 attributs
62.21
Validation des résultats pour 18000 attributs
61.66
Validation des résultats pour 21000 attributs
61.33
Validation des résultats pour 24000 attributs
61.33
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.77
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
61.22
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
63.20
Validation des résultats pour 18000 attributs
62.87
Validation des résultats pour 21000 attributs
62.65
Validation des résultats pour 24000 attributs
62.65
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
62.65
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.88
Validation des résultats pour 6000 attributs
60.99
Validation des résultats pour 9000 attributs
60.99
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.77
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.22
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.66
Validation des résultats pour 27000 attributs
60.66
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.10
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.33
Validation des résultats pour 18000 attributs
60.33
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.33
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
79.47
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
80.13
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.12
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
80.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.15
Validation des résultats pour 18000 attributs
78.15
Validation des résultats pour 21000 attributs
78.15
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.15
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.15
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
82.12
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
81.79
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
81.79
Validation des résultats pour 27000 attributs
81.79
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.15
Validation des résultats pour 6000 attributs
76.82
Validation des résultats pour 9000 attributs
76.82
Validation des résultats pour 12000 attributs
76.82
Validation des résultats pour 15000 attributs
76.82
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
79.80
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
80.13
Validation des résultats pour 15000 attributs
80.79
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
81.13
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
79.80
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_AP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.81
Validation des résultats pour 15000 attributs
78.81
Validation des résultats pour 18000 attributs
78.81
Validation des résultats pour 21000 attributs
78.81
Validation des résultats pour 24000 attributs
78.81
Validation des résultats pour 27000 attributs
78.81
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
78.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
76.16
Validation des résultats pour 15000 attributs
76.16
Validation des résultats pour 18000 attributs
76.16
Validation des résultats pour 21000 attributs
76.16
Validation des résultats pour 24000 attributs
76.16
Validation des résultats pour 27000 attributs
76.16
Validation des résultats pour 30000 attributs
76.16
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.16
Validation des résultats pour 6000 attributs
76.49
Validation des résultats pour 9000 attributs
75.50
Validation des résultats pour 12000 attributs
75.50
Validation des résultats pour 15000 attributs
75.83
Validation des résultats pour 18000 attributs
76.82
Validation des résultats pour 21000 attributs
76.82
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
76.82
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
76.82
Validation des résultats pour 6000 attributs
76.16
Validation des résultats pour 9000 attributs
76.16
Validation des résultats pour 12000 attributs
75.83
Validation des résultats pour 15000 attributs
76.49
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
76.49
Validation des résultats pour 24000 attributs
76.82
Validation des résultats pour 27000 attributs
76.82
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
Tester sans ponctuation (1T (NORM:1 a 3) et 3T (NORM:1 a 3))
corpus/train_cln_1T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.44
Validation des résultats pour 18000 attributs
61.44
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.44
Validation des résultats pour 27000 attributs
61.44
Validation des résultats pour 30000 attributs
61.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.76
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.43
Validation des résultats pour 12000 attributs
63.09
Validation des résultats pour 15000 attributs
62.98
Validation des résultats pour 18000 attributs
62.65
Validation des résultats pour 21000 attributs
62.21
Validation des résultats pour 24000 attributs
62.32
Validation des résultats pour 27000 attributs
62.65
Validation des résultats pour 30000 attributs
62.76
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
62.32
Validation des résultats pour 6000 attributs
61.88
Validation des résultats pour 9000 attributs
62.10
Validation des résultats pour 12000 attributs
62.32
Validation des résultats pour 15000 attributs
62.65
Validation des résultats pour 18000 attributs
62.10
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.88
Validation des résultats pour 30000 attributs
62.10
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
60.77
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.77
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
61.10
Validation des résultats pour 18000 attributs
60.77
Validation des résultats pour 21000 attributs
60.88
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.88
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.66
Validation des résultats pour 12000 attributs
60.77
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.55
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.44
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.77
Validation des résultats pour 15000 attributs
61.77
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.77
Validation des résultats pour 27000 attributs
61.77
Validation des résultats pour 30000 attributs
61.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.99
Validation des résultats pour 6000 attributs
62.10
Validation des résultats pour 9000 attributs
63.09
Validation des résultats pour 12000 attributs
63.20
Validation des résultats pour 15000 attributs
62.87
Validation des résultats pour 18000 attributs
62.32
Validation des résultats pour 21000 attributs
61.77
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
62.21
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.66
Validation des résultats pour 6000 attributs
61.66
Validation des résultats pour 9000 attributs
62.21
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.76
Validation des résultats pour 18000 attributs
61.33
Validation des résultats pour 21000 attributs
61.44
Validation des résultats pour 24000 attributs
61.55
Validation des résultats pour 27000 attributs
61.66
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.55
Validation des résultats pour 6000 attributs
60.66
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.44
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.44
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.77
Validation des résultats pour 6000 attributs
60.88
Validation des résultats pour 9000 attributs
60.55
Validation des résultats pour 12000 attributs
60.44
Validation des résultats pour 15000 attributs
60.66
Validation des résultats pour 18000 attributs
60.66
Validation des résultats pour 21000 attributs
60.55
Validation des résultats pour 24000 attributs
60.77
Validation des résultats pour 27000 attributs
60.77
Validation des résultats pour 30000 attributs
60.77
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.66
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.55
Validation des résultats pour 15000 attributs
60.55
Validation des résultats pour 18000 attributs
60.44
Validation des résultats pour 21000 attributs
60.77
Validation des résultats pour 24000 attributs
60.44
Validation des résultats pour 27000 attributs
60.44
Validation des résultats pour 30000 attributs
60.66
----------------------------------------------------------------------------------------------------
corpus/train_cln_1T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.88
Validation des résultats pour 6000 attributs
61.77
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
61.99
Validation des résultats pour 18000 attributs
61.99
Validation des résultats pour 21000 attributs
61.99
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.99
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.22
Validation des résultats pour 6000 attributs
61.22
Validation des résultats pour 9000 attributs
61.88
Validation des résultats pour 12000 attributs
61.88
Validation des résultats pour 15000 attributs
62.32
Validation des résultats pour 18000 attributs
61.77
Validation des résultats pour 21000 attributs
61.88
Validation des résultats pour 24000 attributs
61.99
Validation des résultats pour 27000 attributs
61.99
Validation des résultats pour 30000 attributs
61.88
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
61.55
Validation des résultats pour 6000 attributs
61.10
Validation des résultats pour 9000 attributs
61.55
Validation des résultats pour 12000 attributs
61.55
Validation des résultats pour 15000 attributs
61.66
Validation des résultats pour 18000 attributs
62.76
Validation des résultats pour 21000 attributs
62.10
Validation des résultats pour 24000 attributs
61.88
Validation des résultats pour 27000 attributs
61.22
Validation des résultats pour 30000 attributs
61.66
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.22
Validation des résultats pour 6000 attributs
59.89
Validation des résultats pour 9000 attributs
60.11
Validation des résultats pour 12000 attributs
60.11
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
60.00
Validation des résultats pour 24000 attributs
60.00
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.00
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.33
Validation des résultats pour 12000 attributs
60.33
Validation des résultats pour 15000 attributs
60.22
Validation des résultats pour 18000 attributs
60.11
Validation des résultats pour 21000 attributs
60.44
Validation des résultats pour 24000 attributs
60.55
Validation des résultats pour 27000 attributs
60.55
Validation des résultats pour 30000 attributs
60.55
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
60.99
Validation des résultats pour 6000 attributs
60.33
Validation des résultats pour 9000 attributs
60.44
Validation des résultats pour 12000 attributs
60.22
Validation des résultats pour 15000 attributs
60.00
Validation des résultats pour 18000 attributs
60.00
Validation des résultats pour 21000 attributs
59.89
Validation des résultats pour 24000 attributs
60.22
Validation des résultats pour 27000 attributs
60.00
Validation des résultats pour 30000 attributs
60.33
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_1_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.47
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.47
Validation des résultats pour 21000 attributs
79.47
Validation des résultats pour 24000 attributs
79.47
Validation des résultats pour 27000 attributs
79.47
Validation des résultats pour 30000 attributs
79.47
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
82.45
Validation des résultats pour 6000 attributs
81.46
Validation des résultats pour 9000 attributs
82.45
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.46
Validation des résultats pour 18000 attributs
82.78
Validation des résultats pour 21000 attributs
82.45
Validation des résultats pour 24000 attributs
82.78
Validation des résultats pour 27000 attributs
82.78
Validation des résultats pour 30000 attributs
82.45
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.79
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
82.78
Validation des résultats pour 12000 attributs
82.78
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.46
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.48
Validation des résultats pour 12000 attributs
77.48
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.47
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
81.13
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
80.13
Validation des résultats pour 18000 attributs
80.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
81.13
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
79.14
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
80.46
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.79
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
81.46
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_2_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.15
Validation des résultats pour 6000 attributs
78.48
Validation des résultats pour 9000 attributs
78.48
Validation des résultats pour 12000 attributs
78.48
Validation des résultats pour 15000 attributs
78.48
Validation des résultats pour 18000 attributs
78.48
Validation des résultats pour 21000 attributs
78.48
Validation des résultats pour 24000 attributs
78.48
Validation des résultats pour 27000 attributs
78.48
Validation des résultats pour 30000 attributs
78.48
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.13
Validation des résultats pour 9000 attributs
81.79
Validation des résultats pour 12000 attributs
81.46
Validation des résultats pour 15000 attributs
81.79
Validation des résultats pour 18000 attributs
82.45
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.12
Validation des résultats pour 27000 attributs
82.45
Validation des résultats pour 30000 attributs
82.78
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.46
Validation des résultats pour 6000 attributs
82.78
Validation des résultats pour 9000 attributs
82.12
Validation des résultats pour 12000 attributs
82.12
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
80.79
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.79
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
77.15
Validation des résultats pour 9000 attributs
77.15
Validation des résultats pour 12000 attributs
77.15
Validation des résultats pour 15000 attributs
77.15
Validation des résultats pour 18000 attributs
77.15
Validation des résultats pour 21000 attributs
77.15
Validation des résultats pour 24000 attributs
77.15
Validation des résultats pour 27000 attributs
77.15
Validation des résultats pour 30000 attributs
77.15
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.79
Validation des résultats pour 6000 attributs
80.46
Validation des résultats pour 9000 attributs
80.13
Validation des résultats pour 12000 attributs
80.46
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.46
Validation des résultats pour 21000 attributs
82.12
Validation des résultats pour 24000 attributs
82.45
Validation des résultats pour 27000 attributs
82.12
Validation des résultats pour 30000 attributs
82.12
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
80.13
Validation des résultats pour 9000 attributs
79.14
Validation des résultats pour 12000 attributs
79.80
Validation des résultats pour 15000 attributs
79.47
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.80
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
81.13
Validation des résultats pour 30000 attributs
81.79
----------------------------------------------------------------------------------------------------
corpus/train_cln_3T_nrm_3_SP.txt
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.81
Validation des résultats pour 6000 attributs
78.81
Validation des résultats pour 9000 attributs
78.81
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
79.14
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
79.14
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
80.46
Validation des résultats pour 6000 attributs
79.14
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.13
Validation des résultats pour 15000 attributs
81.13
Validation des résultats pour 18000 attributs
81.13
Validation des résultats pour 21000 attributs
81.46
Validation des résultats pour 24000 attributs
81.46
Validation des résultats pour 27000 attributs
81.46
Validation des résultats pour 30000 attributs
81.13
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
81.13
Validation des résultats pour 6000 attributs
81.79
Validation des résultats pour 9000 attributs
81.46
Validation des résultats pour 12000 attributs
81.79
Validation des résultats pour 15000 attributs
80.46
Validation des résultats pour 18000 attributs
80.79
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.46
Validation des résultats pour 27000 attributs
80.79
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 3), preprocessor=None, stop_words=None,
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


1


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.81
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
77.81
Validation des résultats pour 12000 attributs
77.81
Validation des résultats pour 15000 attributs
77.81
Validation des résultats pour 18000 attributs
77.81
Validation des résultats pour 21000 attributs
77.81
Validation des résultats pour 24000 attributs
77.81
Validation des résultats pour 27000 attributs
77.81
Validation des résultats pour 30000 attributs
77.81
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 1), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


2


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
77.48
Validation des résultats pour 6000 attributs
78.15
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
78.15
Validation des résultats pour 15000 attributs
79.80
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.46
Validation des résultats pour 24000 attributs
80.13
Validation des résultats pour 27000 attributs
79.80
Validation des résultats pour 30000 attributs
80.46
----------------------------------------------------------------------------------------------------
----------------------------------------------------------------------------------------------------
CountVectorizer(analyzer='word', binary=False, decode_error='strict',
        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',
        lowercase=True, max_df=1.0, max_features=30000, min_df=1,
        ngram_range=(1, 2), preprocessor=None, stop_words='english',
        strip_accents=None, token_pattern='(?u)\\b\\w\\w+\\b',
        tokenizer=None, vocabulary=None)


3


----------------------------------------------------------------------------------------------------
Validation des résultats pour 3000 attributs
78.48
Validation des résultats pour 6000 attributs
77.48
Validation des résultats pour 9000 attributs
78.15
Validation des résultats pour 12000 attributs
79.14
Validation des résultats pour 15000 attributs
79.14
Validation des résultats pour 18000 attributs
79.14
Validation des résultats pour 21000 attributs
80.13
Validation des résultats pour 24000 attributs
79.14
Validation des résultats pour 27000 attributs
79.14
Validation des résultats pour 30000 attributs
80.13
----------------------------------------------------------------------------------------------------

Process finished with exit code 0

